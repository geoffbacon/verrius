{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis and preprocessing\n",
    "\n",
    "In this notebook, I perform some exploratory data analysis (EDA) of the EvaLatin dataset. Then, using what I've learnt about the data I preprocess it for the modeling stage.\n",
    "\n",
    "## Exploratory data analysis\n",
    "\n",
    "In this section, I want to find insights that I can leverage in the modeling stage. This analysis is structured in four sections, each focusing on a different level of the data:\n",
    "\n",
    "1. Dataset\n",
    "2. Forms\n",
    "3. POS\n",
    "4. Lemmata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import OrderedDict\n",
    "import pathlib\n",
    "import fileinput\n",
    "import pyconll\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from segments import Profile, Tokenizer\n",
    "\n",
    "\n",
    "from filenames import ROOT, RAW_EVALATIN_TRAINING_DATA_DIR, PROCESSED_EVALATIN_POS_TRAIN_DATA\n",
    "\n",
    "os.chdir(ROOT)\n",
    "BLUE = sns.color_palette()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all data into a single pyconll CoNLL structure\n",
    "path = pathlib.Path(RAW_EVALATIN_TRAINING_DATA_DIR)\n",
    "f = fileinput.input(path.glob(\"*.conllu\"))\n",
    "conll = pyconll.unit.conll.Conll(f)\n",
    "\n",
    "# Read in all data into a pandas DataFrame\n",
    "data = []\n",
    "for sentence in conll:\n",
    "    for token in sentence:\n",
    "        d = {\"form\": token.form, \"lemma\": token.lemma, \"pos\": token.upos}\n",
    "        data.append(d)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- There are 14,399 sentences in the training data.\n",
    "- There are 259,645 tokens in the training data. The official guidelines say 259,646 but I'm not too worried about this discrepency.\n",
    "- Most (75%) sentences have under 24 tokens, with the average having 18. The vast majority (95%) of sentences have at most 40 tokens.\n",
    "- There are no punctuation or end of sentence markers.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Both the POS and lemmatization task make most sense at the sentence level, although you could try type-level approaches.\n",
    "- The dataset is sizeable but not huge, so it could be worth investigating external unlabelled data, external labelled data and data augmentation methods\n",
    "- Sentence lengths aren't too long, so models forgetting context is not a pressing concern.\n",
    "- We'll have to add beginning and end of sentence markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sentences are there?\n",
    "len(conll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many tokens are there?\n",
    "sum(map(len, conll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of sentence length?\n",
    "sentence_lengths = pd.Series([len(s) for s in conll])\n",
    "sentence_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we show sentence length visually\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.xlim((0, 100))\n",
    "sns.distplot(sentence_lengths, bins=300, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows the percent of sentences with at most 40 tokens.\n",
    "(sentence_lengths <= 40).value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forms\n",
    "\n",
    "N.B. This counts characters not graphemes.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- There are 43,767 unique forms in the training data, of which more than half (24,376) only appear once. The vast majority (90%) of forms appear at most 7 times in the training data.\n",
    "- Most forms have at most 8 characters, with the average form having around 6. The vast majority (95%) of words have at most 10 characters.\n",
    "- There are 126 different characters in the training data.\n",
    "- These characters fall into one of four classes:\n",
    "    - Latin\n",
    "    - Greek\n",
    "    - Full stop\n",
    "    - Other\n",
    "- Over 98% of the Latin characters are lower case.\n",
    "- Full stops are used in four different ways:\n",
    "    - In abbreviations of proper nouns (following the regex `[A-Z].*\\.`)\n",
    "    - In lacunae (following the regex `\\.\\.\\.`)\n",
    "    - For the noun \"salus\", almost always preceded by \"suus\".\n",
    "    - Other abbreviations, whose full form is not found elsewhere in the sentence.\n",
    "- Capitalization is used in four different ways:\n",
    "    - As the first character of a sentence\n",
    "    - As the first character of a proper noun (abbreviated and not)\n",
    "    - In Roman numerals\n",
    "    - In \"HS\"\n",
    "- About half the forms that end with \"-que\" are the clitic \"-que\".\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- The large number of forms, and especially the large number of hapax legomena, suggest the need to include character-based methods.\n",
    "- The large number of forms with few examples in the training data suggest that the test data will also have many infrequent forms too. This lends further support for character-based methods, and context-based methods.\n",
    "- We can massively reduce the size of the character vocabulary by focusing on Latin characters.\n",
    "- If we're just focusing on Latin characters, we could again halve the size of the character vocabulary if we focus on lower case characters. However, they are a huge signal for proper nouns (abbreviated or not).\n",
    "- We could replace all Greek words with a single Greek character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of number of characters per form?\n",
    "word_lengths = df[\"form\"].str.len()\n",
    "word_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows the percent of words with at most 10 characters.\n",
    "(word_lengths <= 10).value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the character set used in the forms?\n",
    "chars = pd.Series(list(\"\".join(df[\"form\"].values)))\n",
    "chars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What classes of characters are there?\n",
    "char_class = lambda ch: unicodedata.name(ch).split()[0]\n",
    "pd.Series(chars.unique()).apply(char_class).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of upper and lower Latin characters?\n",
    "is_latin = lambda ch: char_class(ch) == \"LATIN\"\n",
    "case = lambda ch: \"upper\" if ch.isupper() else \"lower\"\n",
    "chars_df = chars.to_frame(\"char\")\n",
    "chars_df[\"latin\"] = chars_df[\"char\"].apply(is_latin)\n",
    "chars_df[\"case\"] = chars_df[\"char\"].apply(case)\n",
    "chars_df[chars_df[\"latin\"]][\"case\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are full stops used?\n",
    "full_stop_pattern = re.compile(r\"\\.\")\n",
    "has_full_stop = df[\"form\"].str.contains(full_stop_pattern)\n",
    "df[has_full_stop][\"pos\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abbreviations\n",
    "abbreviation_pattern = re.compile(r\"[A-Z].*\\.\")\n",
    "is_abbreviation = df[\"form\"].str.contains(abbreviation_pattern)\n",
    "df[is_abbreviation][\"pos\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lacunae\n",
    "lacuna_pattern = re.compile(r\"\\.\\.\\.\")\n",
    "is_lacuna = df[\"form\"].str.contains(lacuna_pattern)\n",
    "df[is_lacuna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salus\n",
    "is_salus = df[\"lemma\"] == \"salus\"\n",
    "pd.Series(\n",
    "    [df.loc[i - 1][\"form\"] for i in df[has_full_stop & is_salus].index]\n",
    ").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining\n",
    "df[has_full_stop & ~is_abbreviation & ~is_lacuna & ~is_salus][\"form\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is capitalization used?\n",
    "capital_pattern = re.compile(r\"[A-Z]\")\n",
    "has_capital_letter = df[\"form\"].str.contains(capital_pattern)\n",
    "df[has_capital_letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique forms are there?\n",
    "len(df[\"form\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many hapax legomena are there?\n",
    "word_counts = df[\"form\"].value_counts()\n",
    "(word_counts == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(word_counts <= 7).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many forms have the clitic \"-que\"?\n",
    "que_form = df[\"form\"].str.endswith(\"que\")\n",
    "df[que_form][\"lemma\"].str.endswith(\"que\").value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- There are 15 different POS tags, just as the official guideline states.\n",
    "- Nouns and verbs are by far the most frequent POS tags.\n",
    "- By frequency, there are three classes of POS tags:\n",
    "    - NOUN and VERB are in the most frequenct class, each accounting for around 23% of all tokens, totalling over 45% together. \n",
    "    - The next class consists of ADJ, ADV, PRON, DET, CCONJ, ADP, PROPN, SCONJ and PART tags, and each account for 1-8% of tags.\n",
    "    - The last class consists of AUX, NUM, X and INTJ tags, which each account for less than 1% of tokens.\n",
    "- NOUN, VERB, ADJ and PRON need root, morphology and syntactic context to identify them.\n",
    "- ADV, DET, ADP and CCONJ are more tied to a particular form/root.\n",
    "- PART is only negatives \"non\", \"ne\" and \"haud\",  but these can also be SCONJ or ADV.\n",
    "- AUX are forms of sum or eo, as the official guide mentions.\n",
    "- NUM are cardinal numbers or roman numerals.\n",
    "- INTJ can largely be distinguished by their form, which comes from a small set of forms (most are \"O\" or \"hercule\"). However, there is still variation (\"age\", \"malus\"). Context should identify them. Most of the \"O\" INTJ are sentence-initial.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- As a baseline, if you just guessed NOUN for each token, you'd have an accuracy of 23%.\n",
    "- The different information useful to identify the POS are root, the inflectional morphology, the derivational morphology, the syntactic context and the linear order in the sentence.\n",
    "- Having contextual models is important.\n",
    "- Having word-type representations is important for those tags that are strongly lexical (e.g. CCONJ, DET, ADV, INTJ).\n",
    "- Having character-based models is important for those with morphology.\n",
    "- Having sentence position information will help identify some tags (e.g. INTJ), so we should include beginning and end of sentence markers.\n",
    "- Add end of word markers to help model suffixes.\n",
    "- Start/end sentence marker, start/end word marker, characters and type representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many POS tags are there?\n",
    "len(df[\"pos\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of POS tags?\n",
    "df[\"pos\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we show it visually with raw counts\n",
    "order = df[\"pos\"].value_counts().index\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x=\"pos\", data=df, order=order, color=BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do NOUN look like?\n",
    "# Not much here beyond normal Latin morphology\n",
    "noun = df[\"pos\"] == \"NOUN\"\n",
    "noun_counts = df[noun][\"form\"].value_counts()\n",
    "noun_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do VERB look like?\n",
    "# Not much here beyond normal Latin morphology\n",
    "verb = df[\"pos\"] == \"VERB\"\n",
    "verb_counts = df[verb][\"form\"].value_counts()\n",
    "verb_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do ADJ look like?\n",
    "# Not much here beyond normal Latin morphology\n",
    "adj = df[\"pos\"] == \"ADJ\"\n",
    "adj_counts = df[adj][\"form\"].value_counts()\n",
    "adj_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do ADV look like?\n",
    "adv = df[\"pos\"] == \"ADV\"\n",
    "adv_counts = df[adv][\"form\"].value_counts()\n",
    "adv_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do PRON look like?\n",
    "pron = df[\"pos\"] == \"PRON\"\n",
    "pron_counts = df[pron][\"form\"].value_counts()\n",
    "pron_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do DET look like?\n",
    "det = df[\"pos\"] == \"DET\"\n",
    "det_counts = df[det][\"form\"].value_counts()\n",
    "det_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do CCONJ look like?\n",
    "cconj = df[\"pos\"] == \"CCONJ\"\n",
    "cconj_counts = df[cconj][\"form\"].str.lower().value_counts()\n",
    "cconj_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do ADP look like?\n",
    "adp = df[\"pos\"] == \"ADP\"\n",
    "adp_counts = df[adp][\"form\"].str.lower().value_counts()\n",
    "adp_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do PART look like?\n",
    "part = df[\"pos\"] == \"PART\"\n",
    "part_counts = df[part][\"form\"].str.lower().value_counts()\n",
    "part_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = [\"non\", \"ne\", \"haud\"]\n",
    "df[df[\"form\"].isin(negatives)][\"pos\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do PROPN look like?\n",
    "propn = df[\"pos\"] == \"PROPN\"\n",
    "df[propn][\"form\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do AUX look like?\n",
    "aux = df[\"pos\"] == \"AUX\"\n",
    "aux_counts = df[aux][\"form\"].str.lower().value_counts()\n",
    "aux_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do NUM look like?\n",
    "num = df[\"pos\"] == \"NUM\"\n",
    "num_counts = df[num][\"form\"].str.lower().value_counts()\n",
    "num_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do INTJ look like?\n",
    "intj = df[\"pos\"] == \"INTJ\"\n",
    "df[intj][\"form\"].str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many O's begin a sentence?\n",
    "len([sentence for sentence in conll if sentence[0].form.lower() == \"o\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do X look like?\n",
    "X = df[\"pos\"] == \"X\"\n",
    "df[X][\"lemma\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- There are 9,623 unique lemmata.\n",
    "- sum, qui and et each account for over 2% of tokens.\n",
    "- The top 20 lemmata account for almost a quarter of all tokens.\n",
    "- A third of the training data have the lemma identical to the form.\n",
    "\n",
    "\n",
    "#### Notes\n",
    "- Lacunae can be lemmatized with the regular expression `\\.\\.`\n",
    "- Greek words can be lemmatized with the `is_greek_function`.\n",
    "- The Roman numeral regex isn't working well enough at the moment to use it. It makes more false positives than true positives in the training data, although it makes no (correct) false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many lemmata are there?\n",
    "len(df[\"lemma\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of lemata?\n",
    "(df[\"lemma\"].value_counts(normalize=True) * 100).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of lemma?\n",
    "# Now we show it visually with raw counts for the top N lemmata\n",
    "N = 20\n",
    "order = df[\"lemma\"].value_counts().iloc[:N].index\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x=\"lemma\", data=df, order=order, color=BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"lemma\"].value_counts(normalize=True) * 100).iloc[:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution of number of POS tags per lemma?\n",
    "num_pos_per_lemma = df.groupby(\"lemma\")[\"pos\"].nunique().to_frame(\"count\")\n",
    "num_pos_per_lemma[\"count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often are the form and lemma identical?\n",
    "(df[\"form\"].str.lower() == df[\"lemma\"]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lacunae\n",
    "is_lacuna = df[\"lemma\"] == \"uox_lacunosa\"\n",
    "has_two_periods = df[\"form\"].str.contains(\"\\.\\.\")\n",
    "df[is_lacuna] == df[has_two_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greek words\n",
    "def is_greek_char(ch):\n",
    "    return char_class(ch) == \"GREEK\"\n",
    "\n",
    "\n",
    "def is_greek_word(word):\n",
    "    return any(map(is_greek_char, word))\n",
    "\n",
    "\n",
    "# Does the `is_greek_word` function find only Greek words?\n",
    "df[df[\"form\"].apply(is_greek_word)][\"lemma\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the `is_greek_word` function miss any Greek words?\n",
    "(df[~df[\"form\"].apply(is_greek_word)][\"lemma\"] == \"uox_graeca\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roman numerals\n",
    "roman_numeral_pattern = re.compile(\n",
    "    r\"^M{0,4}(CM|CD|D?C{0,4})(XC|XL|L?X{0,4})(IX|I[VU]|[VU]?I{0,4})$\", re.IGNORECASE\n",
    ")\n",
    "is_really_roman_numeral = df[\"lemma\"] == \"numerus_romanus\"\n",
    "is_predicted_roman_numeral = df[\"form\"].str.match(roman_numeral_pattern)\n",
    "df[~is_really_roman_numeral & is_predicted_roman_numeral].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~is_really_roman_numeral & is_predicted_roman_numeral][\n",
    "    \"form\"\n",
    "].str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I replace some types of forms (e.g. Greek words) with placeholder markers because the specifics of their forms don't\n",
    "# matter for these tasks. I also insert start and end markers for word and sentence boundaries. For all these, I want\n",
    "# the marker to be a single token for convenience which do not appear in the cleaned text, and so have chosen Greek\n",
    "# letters for this task. Prior to adding any of these markers, Greek letters from the original text have been removed.\n",
    "\n",
    "GREEK_TOKEN = \"α\"\n",
    "LACUNA_TOKEN = \"β\"\n",
    "PROPN_ABBREVIATION_TOKEN = \"γ\"\n",
    "START_WORD = \"δ\"\n",
    "END_WORD = \"ε\"\n",
    "START_SENTENCE = \"ζ\"\n",
    "END_SENTENCE = \"η\"\n",
    "GRAPHEME_SEPARATOR = \"-\"\n",
    "\n",
    "def remove_other_chars(word):\n",
    "    return \"\".join([ch for ch in word if char_class(ch) in [\"LATIN\", \"GREEK\", \"FULL\"]])\n",
    "\n",
    "def replace_greek_word(word):\n",
    "    if is_greek_word(word):\n",
    "        return GREEK_TOKEN\n",
    "    return word\n",
    "\n",
    "def replace_salus(word):\n",
    "    if word == \"s.\":\n",
    "        return \"salus\"\n",
    "    return word\n",
    "\n",
    "def replace_lacuna(word):\n",
    "    match = re.search(r\"\\.\\.\", word)\n",
    "    if match:\n",
    "        return LACUNA_TOKEN\n",
    "    return word\n",
    "\n",
    "def replace_propn_abbreviation(word):\n",
    "    match = re.match(r\"[A-Z].*\\.\", word)\n",
    "    if match:\n",
    "        return PROPN_ABBREVIATION_TOKEN\n",
    "    return word\n",
    "\n",
    "def replace_full_stop(word):\n",
    "    return word.replace(\".\", \"\")\n",
    "\n",
    "\n",
    "def replace_j(word):\n",
    "    return word.replace(\"j\", \"\")\n",
    "\n",
    "def clean(word):\n",
    "    word = remove_other_chars(word)\n",
    "    word = replace_greek_word(word)\n",
    "    word = replace_salus(word)\n",
    "    word = replace_lacuna(word)\n",
    "    word = replace_propn_abbreviation(word)\n",
    "    word = replace_full_stop(word)\n",
    "    word = replace_j(word)\n",
    "    word = word.lower()  # might not want to do this\n",
    "    return word\n",
    "\n",
    "\n",
    "cleaned = list(df[\"form\"].apply(clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grapheme tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grapheme tokenization profile\n",
    "text = \" \".join(cleaned)\n",
    "profile = Profile.from_text(text)\n",
    "profile.column_labels.remove(\"frequency\")\n",
    "profile.graphemes.pop(\" \")\n",
    "for key in [\"ch\", \"qu\", \"th\", \"rh\", \"ph\", \"gn\"]:\n",
    "    profile.graphemes[key] = OrderedDict([(\"mapping\", key)])\n",
    "    profile.graphemes.move_to_end(key, last=False)\n",
    "with open(\"src/profile.prf\", \"w\") as file:\n",
    "    file.write(str(profile))\n",
    "tokenizer = Tokenizer(\"src/profile.prf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for POS tagging\n",
    "WORD_TAG_DELIMITER = \"/\"\n",
    "WORD_DELIMITER = \"\\t\"\n",
    "\n",
    "lines = []\n",
    "for sentence in conll:\n",
    "    line = []\n",
    "    for token in sentence:\n",
    "        form = tokenizer(clean(token.form), segment_separator=GRAPHEME_SEPARATOR)\n",
    "        form = GRAPHEME_SEPARATOR.join([START_WORD, form, END_WORD])  # add in start/end word boundaries\n",
    "        pos = token.upos\n",
    "        instance = form + WORD_TAG_DELIMITER + pos\n",
    "        line.append(instance)\n",
    "    # add in start/end sentence boundaries\n",
    "    line[0] = START_SENTENCE + GRAPHEME_SEPARATOR + line[0]\n",
    "    line[-1] = line[-1].split(WORD_TAG_DELIMITER)[0] + GRAPHEME_SEPARATOR + END_SENTENCE + WORD_TAG_DELIMITER + pos\n",
    "    lines.append(WORD_DELIMITER.join(line))\n",
    "with open(PROCESSED_EVALATIN_POS_TRAIN_DATA, \"w\") as file:\n",
    "    file.write(\"\\n\".join(lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
